{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = '/data/dumps/bitfpt.train.txt'\n",
    "test = '/data/dumps/bitfpt.test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_gen(data, batch_n):\n",
    "    inds = range(data.shape[0])\n",
    "    np.random.shuffle(inds)\n",
    "    for i in xrange(data.shape[0] / batch_n):\n",
    "        ii = inds[i*batch_n:(i+1)*batch_n]\n",
    "        yield data[ii, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buffered_gen(f, batch_n=1024, buffer_size=2000):\n",
    "    inp = open(f)\n",
    "    data = []\n",
    "    for i, line in enumerate(inp):\n",
    "        data.append(np.array(map(float, line.strip().split('\\t')[1])))\n",
    "        if (i+1) % (buffer_size * batch_n) == 0:\n",
    "            bgen = batch_gen(np.vstack(data), batch_n)\n",
    "            for batch in bgen:\n",
    "                yield batch\n",
    "            data = []\n",
    "    else:\n",
    "        bgen = batch_gen(np.vstack(data[:-1]), batch_n)\n",
    "        for batch in bgen:\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def he_initializer(size):\n",
    "    return tf.random_normal_initializer(mean=0.0, stddev=np.sqrt(1. / size), seed=None, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def linear_layer(tensor, input_size, out_size, init_fn=he_initializer,):\n",
    "    W = tf.get_variable('W', shape=[input_size, out_size], initializer=init_fn(input_size))\n",
    "    b = tf.get_variable('b', shape=[out_size], initializer=tf.constant_initializer(0.1))\n",
    "    return tf.add(tf.matmul(tensor, W), b)\n",
    "\n",
    "def bn_layer(tensor, size, epsilon=0.0001):\n",
    "    batch_mean, batch_var = tf.nn.moments(tensor, [0])\n",
    "    scale = tf.get_variable('scale', shape=[size], initializer=tf.constant_initializer(1.))\n",
    "    beta = tf.get_variable('beta', shape=[size], initializer=tf.constant_initializer(0.))\n",
    "    return tf.nn.batch_normalization(tensor, batch_mean, batch_var, beta, scale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self,\n",
    "                 gpu_config = None,\n",
    "                 batch_size=1024, \n",
    "                 input_space=166,\n",
    "                 middle_layers=None,\n",
    "                 latent_space=10,\n",
    "                 learning_rate=0.001,\n",
    "                 activation_fn=tf.nn.relu,\n",
    "                 initializer=he_initializer):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_space = input_space\n",
    "        if middle_layers is None:\n",
    "            self.middle_layers = [256, 256]\n",
    "        else:\n",
    "            self.middle_layers = middle_layers\n",
    "        self.latent_space = latent_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_fn = activation_fn\n",
    "        self.initializer = initializer\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        self.input_x = tf.placeholder(tf.float32, [None, input_space])\n",
    "        \n",
    "        self._create_network()\n",
    "        self._loss()\n",
    "        \n",
    "        if gpu_config is None:\n",
    "            gpu_config = tf.ConfigProto()\n",
    "            gpu_config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "        \n",
    "        self.sess = tf.Session(config=gpu_config)\n",
    "        self.init_net()\n",
    "\n",
    "    def _create_network(self):\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            self.encoder_layers, self.z_mean, self.z_log_sigma_sq = self._encoder()\n",
    "        \n",
    "        with tf.variable_scope(\"sample\"):\n",
    "            self.eps = tf.random_normal((self.batch_size, self.latent_space), 0, 1, dtype=tf.float32)\n",
    "            self.z = tf.add(self.z_mean, tf.multiply(tf.exp(tf.divide(self.z_log_sigma_sq, 2.0)), self.eps), name=\"z\")\n",
    "        \n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            self.decoder_layers = self._decoder()\n",
    "            self.decoded = self.decoder_layers[-1]\n",
    "    \n",
    "    def _encoder(self):\n",
    "        with tf.variable_scope(\"layer-0\"):\n",
    "            encoder_layers = [linear_layer(self.input_x, self.input_space, self.middle_layers[0])]\n",
    "            \n",
    "        for i in xrange(len(self.middle_layers) - 1):\n",
    "            with tf.variable_scope(\"layer-%i\" % (i+1)):\n",
    "                activated = self.activation_fn(encoder_layers[-1])\n",
    "                normed = bn_layer(activated, self.middle_layers[i])\n",
    "                next_layer = linear_layer(normed, self.middle_layers[i], self.middle_layers[i+1])\n",
    "            encoder_layers.append(next_layer)\n",
    "        \n",
    "        with tf.variable_scope(\"latent\"):\n",
    "            activated = tf.nn.relu(encoder_layers[-1])\n",
    "            with tf.variable_scope(\"mean\"):\n",
    "                z_mean = linear_layer(activated, self.middle_layers[-1], self.latent_space)\n",
    "            with tf.variable_scope(\"log_sigma_sq\"):\n",
    "                z_log_sigma_sq = linear_layer(activated, self.middle_layers[-1], self.latent_space)\n",
    "        \n",
    "        return encoder_layers, z_mean, z_log_sigma_sq\n",
    "    \n",
    "    def _decoder(self):\n",
    "        sizes = self.middle_layers[::-1] + [self.input_space]\n",
    "        with tf.variable_scope(\"layer-0\"):\n",
    "            decoder_layers = [linear_layer(self.z, self.latent_space, sizes[0])]\n",
    "            \n",
    "        for i in xrange(len(sizes) - 1):\n",
    "            with tf.variable_scope(\"layer-%i\" % (i+1)):\n",
    "                activated = self.activation_fn(decoder_layers[-1])\n",
    "                normed = bn_layer(activated, sizes[i])\n",
    "                next_layer = linear_layer(normed, sizes[i], sizes[i+1])\n",
    "            decoder_layers.append(next_layer)\n",
    "        \n",
    "        return decoder_layers\n",
    "        \n",
    "    def _loss(self):\n",
    "        elementwise_logloss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.decoded, labels=self.input_x)\n",
    "        batch_logloss = tf.reduce_sum(elementwise_logloss, 1)\n",
    "        self.ae_loss = tf.reduce_mean(batch_logloss)\n",
    "        \n",
    "        self.latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq - tf.square(self.z_mean) - \\\n",
    "                                                tf.exp(self.z_log_sigma_sq), 1)\n",
    "        self.cost = tf.reduce_mean(tf.add(batch_logloss, self.latent_loss))\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.cost)\n",
    "\n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=(self.batch_size, self.latent_space))\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(tf.nn.sigmoid(self.decoded), feed_dict={self.z: z_mu})\n",
    "\n",
    "    def init_net(self):\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "    def train(self, log):\n",
    "        sess = self.sess\n",
    "        saver = tf.train.Saver()\n",
    "        hist = []\n",
    "        \n",
    "        for e in xrange(100):\n",
    "            train_gen = buffered_gen(train, batch_n=self.batch_size)\n",
    "            for batch_x in train_gen:\n",
    "                sess.run(self.train_op, feed_dict={self.input_x: batch_x})\n",
    "            else:\n",
    "                print >> log, \"epoch #%d\" % (e+1)\n",
    "                saver.save(sess, './fpt.vae.%de.model.ckpt' % e)\n",
    "                \n",
    "                test_gen = buffered_gen(test, batch_n=self.batch_size)\n",
    "                \n",
    "                test_x = test_gen.next()\n",
    "                loss = sess.run(self.ae_loss, feed_dict={self.input_x: test_x})\n",
    "                print >> log, \"ae_loss: %f\" % loss\n",
    "                log.flush()\n",
    "                hist.append(loss)\n",
    "        return hist\n",
    "    \n",
    "    def load(self, model):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vae = VAE(batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./fpt.vae.log', 'w') as log:\n",
    "    hist1 = vae.train(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vae.load('./fpt.vae.20e.model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npzfile = np.load('./delaney.fpts.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = npzfile['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1144, 168)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_m, encoded_s = vae.sess.run([vae.z_mean, vae.z_log_sigma_sq], feed_dict={vae.input_x: data[:, 2:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded = np.hstack([encoded_m, encoded_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./vae.encoded.fpt', [encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
